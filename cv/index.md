---
title: Curriculum Vitae
author: Jairam
layout: page
permalink: /cv/
---
<p style="text-align:left;">
  <strong>Jairam Chandar</strong><br /> Big Data Engineer<br /> <strong>t </strong>  <a title="Jairam Chandar on Twitter" href="http://twitter.com/jairamc">jairamc</a><br /> <span style="font-size:medium;">☛ </span><a href="http://about.me/jairam" target="_blank">http://about.me/jairam</a> <strong> </strong>
</p>

<h2 style="text-align:left;">
  <span class="Apple-style-span" style="color:#000000;">Professional and Academic Highlights</span>
</h2>

<div style="text-align:left;">
  <ul>
    <li>
      Awarded <strong>Masters in Computer Science</strong> with Distinction from the University of Edinburgh
    </li>
    <li>
      M.Sc. dissertation involved work on Join-Algorithms using <strong>Hadoop</strong>.
    </li>
    <li>
      Experience in managing and using live <strong>NoSql clusters</strong>.
    </li>
    <li>
      Given a <strong>public talk</strong> at Cassandra London meetup on<strong> Hadoop integration in Cassandra</strong>
    </li>
    <li>
      Worked for Microsoft India for 2 years.
    </li>
    <li>
      <strong>B.Tech. in Computer Science</strong> and Engineering with cumulative GPA of 9.1 (on 10).
    </li>
    <li>
      Awarded Best Student Project during undergraduate course.
    </li>
  </ul>

  <h2>
    Technical Skills
  </h2>

  <ul>
    <li>
      Technologies : <ul>
        <li>
          <strong>Hadoop</strong>
        </li>
        <li>
          <strong>Cassandra</strong>
        </li>
        <li>
          <strong>HBase</strong>
        </li>
        <li>
          <strong>Hive</strong>
        </li>
        <li>
          Java/J2EE
        </li>
      </ul>
    </li>

    <li>
      Languages <ul>
        <li>
          Java
        </li>
        <li>
          Scala
        </li>
        <li>
          C#
        </li>
        <li>
          C++
        </li>
      </ul>
    </li>

    <li>
      Platforms <ul>
        <li>
          <strong>Unix/Linux</strong>
        </li>
        <li>
          Windows
        </li>
      </ul>
    </li>
  </ul>

  <h2>
    Relevant Work Experience
  </h2>

  <h3>
    <strong>Mediasift Ltd. (trading as Datasift Inc.), Reading, UK (September 2011 &#8211; Present)</strong>
  </h3>

  <p>
    Designation &#8211; Big Data Engineer
  </p>

  <p>
    As part of the data-warehousing team at Datasift, primarily responsible for archiving, curating and retrieval of massive amounts of social data accumulated every day. The data is in the order of 2 TB/day. Technologies used include &#8211;
  </p>

  <ul>
    <li>
      Hadoop (Map Reduce / HDFS)
    </li>
    <li>
      HBase
    </li>
  </ul>

  <p>
    Played a key role in development of Historics platform for mining archived social media data for customers.
  </p>

  <h3>
    <strong>Imagini Europe Limited, London, UK (December 2010 &#8211; September 2011)</strong>
  </h3>

  <p>
    Designation &#8211; Back-End Developer
  </p>

  <p>
    Working on Data Warehousing solutions using NoSql technologies. Key player in build, maintenance and use of the following solutions, standalone or in conjunction with each other &#8211;
  </p>

  <ul>
    <li>
      Cassandra – Primary Data-store <ul>
        <li>
          Over 4 TB of data that is used for real-time access and analytics
        </li>
      </ul>
    </li>

    <li>
      Hadoop &#8211; Main analytics engine <ul>
        <li>
          Played a major role in integrating and smooth functioning of the analytics cluster with the data-store. Primarily responsible for generating analytics data using Map/Reduce programs written in Java. Using the knowledge gained, gave a talk at a public meet-up. Podcast available at – <a href="http://skillsmatter.com/podcast/home/cassandra-meetup-march">http://skillsmatter.com/podcast/home/cassandra-meetup-march</a>.
        </li>
      </ul>
    </li>

    <li>
      Hive <ul>
        <li>
          Most of the services hosted on the cloud, events system logs reside on Amazon S3. Responsible for running Hive queries over these logs using Amazon Elastic MapReduce.
        </li>
      </ul>
    </li>
  </ul>

  <h2>
    Relevant Education
  </h2>

  <h3>
    <strong>MSc &#8211; Computer Science (Sept 2009 &#8211; Sept 2010) [Awarded Distinction]</strong>
  </h3>

  <p>
    School of Informatics, University of Edinburgh (Edinburgh, U.K.)
  </p>

  <p>
    Specialization Modules &#8211;
  </p>

  <ul>
    <li>
      Design & Analysis of Parallel Algorithms
    </li>
    <li>
      Advance Databases
    </li>
    <li>
      Distributed Systems
    </li>
    <li>
      Parallel Programming Languages & Systems
    </li>
    <li>
      Human Computer Interaction
    </li>
    <li>
      Compiler Optimisation
    </li>
    <li>
      Text Technologies & Information Retrieval
    </li>
    <li>
      Querying & Storing XML
    </li>
  </ul>

  <p>
    Course work &#8211;
  </p>

  <ol>
    <li>
      <strong>Dissertation</strong> &#8211;<strong> Join algorithms using Map/Reduce</strong> &#8211; Evaluated existing join algorithms used in contemporary systems that use Map/Reduce. Designed two new algorithms for multi-way joins. Properties like selectivity factor of a join were exploited in design of the algorithms. The project was implemented using <strong>Hadoop</strong> and <strong>HDFS</strong>. The coding was entirely done in Java. The evaluation was done based on speed-up, scale-up and network I/O. The thesis has been awarded distinction and is available for download from the University website at <a href="http://www.inf.ed.ac.uk/publications/thesis/online/IM100859.pdf">http://www.inf.ed.ac.uk/publications/thesis/online/IM100859.pdf</a>
    </li>
    <li>
      <strong>Advanced Databases</strong> &#8211; Extended the query engine of a home grown database to implement External Sort and Merge join algorithms. I managed to secure 100% in the coursework and the work was appreciated to be the best amongst the batch.
    </li>
    <li>
      <strong>Information Retrieval</strong> &#8211; Developed a web crawler (using Python) capable of harvesting a set of hyper-linked news stories from a web-server. Implemented content-extraction algorithm using plateau-based method. Also implemented near-duplicate detection feature using SimHash algorithm. Also developed a system for searching images based on keywords (tags). Implemented exact-match, best-match and pseudo-relevance feedback algorithm.
    </li>
    <li>
      <strong>Querying and Storing XML</strong> &#8211; Implemented an algorithm for updating XML via Relational Databases with 2 other collaborators. The project involved incrementally updating recursively stored XML, stored in an existing relational database, as opposed to previous approaches that shred the entire XML document into a newly created database of a newly designed schema.
    </li>
    <li>
      <strong>Distributed Systems</strong> &#8211; Implemented a simulation of Chandy-Lamport snapshot algorithm which is used in distributed systems for recording a consistent global state of an asynchronous system.
    </li>
  </ol>

  <div>
    <h2>
      Previous Work Experience
    </h2>

    <h3>
      <strong>Microsoft India (R&D) Private Limited, Hyderabad, India (June 2007 &#8211; April 2009)</strong>
    </h3>

    <p>
      Designation &#8211; Software Development Engineer
    </p>

    <p>
      All projects involved work on Microsoft Technology Stack. Almost all the coding was done in <strong>C#</strong> and all projects used <strong>Visual Studio Team Suite</strong>.
    </p>

    <h2>
      Previous Education
    </h2>

    <h3>
      <strong>B.Tech &#8211; Computer Science Engineering (July 2003 &#8211; May 2007)</strong>
    </h3>

    <p>
      Amrita School of Engineering, Amrita Vishwa Vidyapeetham (Coimbatore, India)
    </p>

    <ul>
      <li>
        Scored cumulative grade point average of 9.1 (on 10)
      </li>
      <li>
        Won Best Student Project award for a project on Machine Translation as part of my final year student project. The application translates given input text in English to Hindi with acceptable levels of accuracy.
      </li>
    </ul>

    <h2>
      Non-Technical Work Experience
    </h2>

    <h3>
      <strong>Indian School of Business (June 2009 &#8211; August 2009)</strong>
    </h3>

    <p>
      Designation &#8211; Associate, Admissions and Financial Aid
    </p>

    <p>
      Responsibilities-
    </p>

    <ul>
      <li>
        Worked on strengthening the e-marketing initiative for the Admissions Team.
      </li>
      <li>
        <h3>
          Co-ordinated implementation of new CRM system.
        </h3>
      </li>
    </ul>

    <h3>
      <strong>Richmond Place University Accommodation (March 2010 &#8211; Sept 2010)</strong>
    </h3>

    <p>
      Designation &#8211; House Assistant
    </p>

    <p>
      Responsibilities-
    </p>

    <ul>
      <li>
        Assisting the warden in maintaining discipline and decorum.
      </li>
      <li>
        Organizing and managing social events for the residents.
      </li>
    </ul>
  </div>
</div>
